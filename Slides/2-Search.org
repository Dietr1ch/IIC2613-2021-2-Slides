#+title: Search
#+author:
#+email: ddaroch@ing.puc.cl
#+language: en
#+date: AI - 2021 H2
#+REVEAL_ROOT: reveal.js/

* Tasks                                                            :noexport:
** TODO Prepare Slides
** TODO Practice
** TODO Teach
* Config                                                           :noexport:
  #+STARTUP: overview

** Numbering
   #+OPTIONS: toc:nil
   # Remove numbering from sections and subsections
   #+OPTIONS: num:nil

** Reveal
   #+REVEAL_HLEVEL: 2
   #+REVEAL_SPEED: 2
   #+OPTIONS: reveal_slide_number:h.v

   #+REVEAL_EXTRA_CSS: ./style.css

   # Adding plugins without their dependencies might break your slides
   #+REVEAL_EXTRA_JS: { src: 'plugin/math/math.js', async: true }, { src: 'plugin/zoom-js/zoom.js', async: true }
   #+REVEAL_PLUGINS: (highlight markdown notes)

*** Looks
    #+REVEAL_TRANS: slide
    # Theme (black moon night blood)
    #+REVEAL_THEME: black
    # Target 1366x768, 16:9 and not far from 1024x768 widely used on projectors
    #+OPTIONS: reveal_width:1366 reveal_height:768
    # #+REVEAL_EXTRA_CSS: custom.css
*** Reveal
    #+OPTIONS: reveal_center:t
    #+OPTIONS: reveal_progress:t
    #+OPTIONS: reveal_history:nil
    #+OPTIONS: reveal_control:t
    #+OPTIONS: reveal_rolling_links:t
    #+OPTIONS: reveal_keyboard:t
    #+OPTIONS: reveal_overview:t

** Beamer
   #+BEAMER_THEME: Rochester [height=20pt]
   # #+OPTIONS: H:2
   # #+OPTIONS:   H:3 num:t toc:t \n:nil @:t ::t |:t ^:t -:t f:t *:t <:t

* Search Problem
** Path-finding
   Many interesting problems can be framed as Search problem in a Graph.
   #+ATTR_REVEAL: :frag (appear)
   - Nodes can represent specific states of a system/world/game.
   - Edges represent actions that transform the state from one node into another.
   - Example states:
     - Maze: Coordinates of the player.
     - Chess: Board position, castling state and who's to play.
     - Racing game: Points in $(t, \vec{x}, \vec{v}, \theta, \varphi, Gear, Pedals, Wheel)$.
     - Poker: Cards and chips that each player has.
** Sokoban
  #+REVEAL_HTML: </section>
  #+REVEAL_HTML: <section data-background-iframe="https://www.youtube.com/embed/n9YzAK-nuB4?start=25" data-background-interactive>
** Taxonomy
	#+ATTR_REVEAL: :frag (appear)
	- Mode
 		- Cooperative
 		- Adversarial
	- Knowledge
		- Total
		- Partial
	- Determinism
		- Deterministic environment
		- Non-Deterministic environment
	- Ply (turn) time horizon
		- Real-time
		- Unbounded
** Examples

   |-------------------+-------------+-----------+-------------------+--------------|
   | Game              | Mode        | Knowledge | Determinism       | Time horizon |
   |-------------------+-------------+-----------+-------------------+--------------|
   | Maze              | Cooperative | Total     | Deterministic     | Unbounded    |
   | Sokoban           | Cooperative | Total     | Deterministic     | Unbounded    |
   | Time-trial Racing | Cooperative | Total     | Deterministic     | Real-time    |
   | Freecell          | Cooperative | Partial   | Non-Deterministic | Unbounded    |
   |-------------------+-------------+-----------+-------------------+--------------|

   #+REVEAL: split

   |-------------+-------------+-----------+-------------------+--------------|
   | Game        | Mode        | Knowledge | Determinism       | Time horizon |
   |-------------+-------------+-----------+-------------------+--------------|
   | Racing      | Adversarial | Total     | Deterministic     | Real-time    |
   | Chess       | Adversarial | Total     | Deterministic     | Real-time    |
   | Among Us    | Adversarial | Partial   | Deterministic*    | Real-time    |
   | CS:GO       | Adversarial | Partial   | Deterministic*    | Real-time    |
   | Liar's Dice | Adversarial | Partial   | Non-Deterministic | Real-time    |
   | Uno         | Adversarial | Partial   | Non-Deterministic | Real-time    |
   |-------------+-------------+-----------+-------------------+--------------|

   #+LaTeX: \note{
   #+BEGIN_NOTES
   Enter speaker notes here.
   #+END_NOTES
   #+LaTeX: }

** Problem Terminology
   We will need some common terms to talk about path-finding.
	 #+ATTR_REVEAL: :frag (appear)
   - State: A specific configuration of a system.
     - Chess: The board* and who's to play.
   - Action: An specific action that transforms the system's State.
     - Chess: A move by the active player.
   - Search space: The space where points are system states. Related to the
     ~class~ that represents the state.
     - Chess: A way of representing all chess states, like all [[https://en.wikipedia.org/wiki/Forsyth%E2%80%93Edwards_Notation][FEN]] positions.
   - Search state graph: The graph connecting states through actions.
     - Chess: A huge graph where edges are chess moves from one state to another.

   #+LaTeX: \note{
   #+BEGIN_NOTES
   Chess has some subtleties, like castling and draw by repetition.
   #+END_NOTES
   #+LaTeX: }

** Search terminology
	 #+ATTR_REVEAL: :frag (appear)
   - Search problem: $(Space, start, goal)$
     - Chess start: The state representing the starting board position.
     - Chess goal: A function that checks for check-mates
   - Search Tree: The spanning tree of Nodes representing paths on the State
     graph. Built throughout the Search by adding Nodes or updating edges.
   - Expansion: To compute the possible actions that may be performed and their
     resulting states.

** A generic search algorithm
	 #+ATTR_REVEAL: :frag (appear)
    #+begin_src python
     def generic_search_sketch(g: Graph, starting_node, goal_function) -> Solution:
         Closed = set()  # Closed: Explored nodes (We only store the state)
         Open = MagicalCollection()  # Open: Known, but still unexplored Nodes
         Open.add(starting_node)

         while Open:
             node = Open.pop()  # Takes a node from Open. Which one?
             if is_goal(node):
                 return path(node)

             Closed.add(node)
             for n in node.neighbors():  # Creates Nodes around node.state
                 if n.state in Closed:
                     continue
                  Open.upsert(n)  # Insert|Update to keep Nodes a Spanning Tree (if needed)

         return None
    #+end_src


* Search Algorithms
** Depth-first Search
*** A simple implementation
    #+begin_src python
      def _dfs(g: Graph, state: State, q: Query, p: Path) -> Path:
          """Naive-DFS. Might get stuck in a loop."""
          if q.isGoal(state):
              return p

          for s in g.neighbors(state):
              path = _dfs(g, s, q, p+s)
              if path:
                  return path

          return None

      def dfs(g: Graph, s: State, q: Query):
          return _dfs(g, s, q, Path())
    #+end_src

*** DFS v2 - Loop-safe
    #+begin_src python
      def _loop_free_dfs(g: Graph, state: State, q: Query, p: Path, visited: Set[State]) -> Path:
          """Simple-DFS. Checks for loops, but it might run into a Stack Overflow."""
          if q.isGoal(state):
              return g.path_to(state)  # Retrieve the path to state

          if state in visited
              return None
          visited.add(state)

          for a, s in g.neighbors(state):
              path = _loop_free_dfs(g, s, q, p+a)
              if path:
                  return path

          return None

      def loop_free_dfs(g: Graph, s: State, q: Query) -> Path:
          return _loop_free_dfs(g, s, q, Path(), set())
    #+end_src

*** DFS v3 - Bounded stack
    #+begin_src python
      def loop_free_recursion_free_dfs(g: Graph, start: State, q: Query, p: Path) -> Path:
          """DFS with loop detection and no recursion. Now a Generic Search using a Stack."""
          Closed = set()
          Open = Stack()
          Open.push(start)
          g.reach(start, action=None, parent=None)

          while not Open.empty():
              state = Open.pop()

              if q.isGoal(state):
                  return g.path_to(state)  # Retrieve the path to state

              for a, s in s.neighbors():
                  if s in Closed:
                      continue
                  g.reach(s, action=a, parent=state)  # Update the path to s (if needed)
                  Open.push(s)

          return None
    #+end_src

** Breadth-first Search
*** A simple implementation
    #+begin_src python
      def breadth_first_search(g: Graph, start: State, query: Query) -> Path:
          """BFS. A Generic Search using a Queue."""
          Closed = set()
          Open = Queue()
          Open.push(start)
          g.reach(start, action=None, parent=None)

          while not Open.empty():
              state = Open.pop()

              if q.isGoal(state):
                  return g.path_to(state)  # Retrieve the path to state
      
              for s in state.neighbors():
                  if s in Closed or s in Open:
                      continue
                  g.reach(s, action=a, parent=state)  # Record the path to s (if needed)
                  Open.push(s)

          return None
    #+end_src

** Dijkstra's Algorithm
*** Graphs with costs
    #+ATTR_REVEAL: :frag (appear)
    - Many problems have actions that have different costs.
      - Time or effort actions take varies naturally
        - Some roads are longer, climbing stairs takes more time and energy.
    - BFS won't be optimal in cost by being optimal in the number of actions.

*** Solving problems with cost
    #+ATTR_REVEAL: :frag (appear)
    The natural starting point is BFS as it's optimal in the number of actions.
    #+ATTR_REVEAL: :frag (appear)
    - How do we translate BFS's hop-consiousness into cost-consiousness?
      #+ATTR_REVEAL: :frag (appear)
      - Instead of the closest node you can reach, take the cheapest one.
      - Wait, is that enough? What's so smart about this? How is Dijkstra
        famous for it?
        #+ATTR_REVEAL: :frag (appear)
        - Yes; nothing; Invented it while drinking coffee, and also invented
          many more algorithms.

*** Updating Open
    Costs will force us to continuously rank and update  nodes in $Open$.
    #+begin_src dot :file Graphs/search_update_open.png :results show :exports results
      digraph update_open {
        rankdir=LR;

        s->a [label=1];
        a->g [label=3];

        s->b [label=2];
        b->g [label=0];

        s->g [label=5];
      }
    #+end_src
    We will need something more efficient than a list or a stack.
    - A Priority Queue (aka Heap) does exactly what we need. ([[https://docs.python.org/3/library/heapq.html#theory][Python's heapq]])

*** Updating Open
    What should we do here?
    #+begin_src dot :file Graphs/search_update_open2.png :results show :exports results
      digraph update_open2 {
        rankdir=LR;

        s->a [label=1];
        a->g [label=3];

        s->b [label=0];
        b->c [label=7];
        c->d [label=0];

        s->g [label=5];
      }
    #+end_src
    #+ATTR_REVEAL: :frag (appear)
    - Expansions: $(0, s), (0, b), (1, a), (4, g)$.
    - Insertions/Updates: $[(0, s)], [(1, a), (0, b), (5, g)], [(7, c)], [(5\rightarrow 4, g)]$.
    - Final Closed: ${s, b, a}$. Final Open: $(7, c)$. Unknown States: $d$

*** A simple implementation
    #+begin_src python
      def best_first_search(g: Graph, start: State, query: Query) -> Path:
          """Dijkstra's algorithm. Similar to BFS, but prefering lower costs."""
          Closed = set()
          Open = CustomPriorityQueue()  # A Heap with fast updates for existing items
          Open.push(Node(start))

          while not Open.empty():
              node = Open.pop()

              if q.isGoal(node.state):
                  return node.get_path()

              for a, s in state.neighbors():
                  if s in Closed:
                      continue
                  n = Node(s, action=a, parent=state)
                  Open.update_if_better(n)  # Open may already have a Node for s

          return None
    #+end_src

** Smarter decisions
*** Lack of comprehension
    #+ATTR_REVEAL: :frag (appear)
    - Even while Dijkstra's Algorithm is aware of the costs, it still takes
      decisions that humans looking at a (simple) graph wouldn't.
      - We make good guesses on where to head to, even if we don't exactly know
        the solution for the problem.
    - What do we really think about when solving search problems?
      - We sense that some States are better than others as they seem to be
        closer to the goals.
      - We estimate the remaining cost.

*** What if we could estimate?
    #+ATTR_REVEAL: :frag (appear)
    - Say we had a function $estimate: State \rightarrow \mathbb{R}_0^+$
    - We could tie-break based on the estimated cost.
      - For equally expensive nodes from Open, we would prefer the one that
        seems closer
    - Can we do better?

*** Rethinking costs
    #+ATTR_REVEAL: :frag (appear)
    With a known cost to a Node, and an estimated remaining cost to reach a goal,
    we can guess what's the cost of a solution that goes the Node.
    #+ATTR_REVEAL: :frag (appear)
    - Instead of only ranking with $cost: Node \rightarrow \mathbb{R}_0^+$ we
      can also consider the estimated remaining cost.
      #+ATTR_REVEAL: :frag (appear)
      - $solution\_cost: Node \rightarrow \mathbb{R}_0^+$
      - $solution\_cost(n) = cost(n) + estimate(n.state)$
      - Actually known as $f(n) = g(n) + h(n.state)$

*** Heuristics
    #+ATTR_REVEAL: :frag (appear)
    - How do we estimate costs of a path we don't know yet?
    - What if we estimate costs poorly?
      - What's a poor estimation?
        - $h(s) = 0$ is a function from $State \rightarrow \mathbb{R}_0^+$.
          - With this we are back to using Dijkstra's algorithm?
        - What if we under-estimate the cost?
        - What if we over-estimate the cost?
        - Can we improve our estimations as we go?

*** A*
    #+ATTR_REVEAL: :frag (appear)
    $A^*$ is the search algorithm that ranks nodes with $f(n)=g(n)+h(n.state)$.
    - Is it better? Is it the best?
      - Well, it depends on how good the heuristic is.

*** What's a good heuristic?
    #+ATTR_REVEAL: :frag (appear)
    - $h(s)=0$ is definitely not good.
      #+ATTR_REVEAL: :frag (appear)
      - Not the worst, at least you fallback to Dijkstra's Algorithm, which works and gets optimal solutions.
      - Really? What's worse than $h(s)=0$?
        #+ATTR_REVEAL: :frag (appear)
        - A misguiding heuristic. What if $h(g)=\infty$ for every goal state?
          #+ATTR_REVEAL: :frag (appear)
          - [[https://youtu.be/vde6rOO5AbU?t=32][That's evil]]! With that we would miss the goal!
          - True. With bad heuristics $A^*$ may not be complete nor correct.
    #+ATTR_REVEAL: :frag (appear)
    - If $h(s)$ was the actual cost to the solution it would be really good.
      #+ATTR_REVEAL: :frag (appear)
      - Indeed, but computing that is solving the search problem at hand.
      - This perfect heuristic, called $h^*(s)$, is a good reference heuristic.

*** So, what's a good heuristic?
    #+ATTR_REVEAL: :frag (appear)
    - A good heuristic must not drive us away from a goal.
      #+ATTR_REVEAL: :frag (appear)
      - $0 \leq h(s) \leq h^*(s)$
        #+ATTR_REVEAL: :frag (appear)
        - $f(n)$ would always be a lower bound for the cost.
        - Otherwise we may defer expanding nodes in the optimal path for too
          long and find a sub-optimal path first.
        - Known as admissibility.
      - Is this enough? No

*** A stronger heuristic property
    #+begin_src dot :file Graphs/search_inconsistent_h.png :results show :exports results
      digraph inconsistent_h {
        rankdir=LR;

        s [label="S\nh=4"];
        a [label="A\nh=3"];
        b [label="B\nh=0"];
        g [label="G\nh=0"];

        s->a [label=1];
        s->b [label=3];
        a->b [label=1];
        b->g [label=2];
      }
    #+end_src
    #+ATTR_REVEAL: :frag (appear)
    - This is admissible and almost $h^*(s)$, the only difference is on $B$.
      #+ATTR_REVEAL: :frag (appear)
      - $A^*$ gets misdirected. What's so wrong with $h(B)=0$?
      - It tells us that $B$ is really good and $B$ gets in $Closed$ too early.

*** Consistency
    [[file:Graphs/search_inconsistent_h.png]]
    #+ATTR_REVEAL: :frag (appear)
    - The trick here is likely be on $h(B)=0$. $h=h^*$ on the other states.
      #+ATTR_REVEAL: :frag (appear)
      - BFS and Dijkstra expand nodes with non-decreasing steps / cost.
      - But this glitch in $h(B)$ makes $f(S)=4$ drop down to $f(B)=3$
    - Consistency:
      #+ATTR_REVEAL: :frag (appear)
      - $h(n) \leq c(n, a, n') + h(n')$
      - $g(n) + h(n) \leq g(n) + c(n, a, n') + h(n')$
      - $f(n) \leq f(n')$

*** Optimality
    #+ATTR_REVEAL: :frag (appear)
    - Is $A^*$ finally optimal when using a consistent heuristic?
      #+ATTR_REVEAL: :frag (appear)
      - Yes, and we can get a slightly more general result for free.
      - w-$A^*$ is w-optimal.
        #+ATTR_REVEAL: :frag (appear)
        - $f_w(n) = g(s) + w*h(n)$ produces solutions no more than $w$ times
          more expensive than the optimal.
        - This makes the fringe deform even further towards the goals.

*** Engineering heuristics
    #+ATTR_REVEAL: :frag (appear)
    - We can disassemble a problem without affecting the heuristic properties.
      #+ATTR_REVEAL: :frag (appear)
      - Removing an action/edge keeps a heuristic admissible.
      - Removing an action/edge keeps a heuristic consistent.
    - Can we devise a problem with more actions and solve it perfectly?
      #+ATTR_REVEAL: :frag (appear)
      - This problem is called a relaxation.
      - Solving it with a consistent heuristic, like $h^*$ would give us a
        consistent (and admissible) heuristic for our actual problem.
